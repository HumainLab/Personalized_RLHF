{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will\n",
    "1. reorganize the original PRISM dataset into \"prism_data_user.json\" and \"prism_data_dialog.json\";\n",
    "2. split the train/test dataset in \"prism_split_ids.json\";\n",
    "3. select 50 dialogues for win-rate evaluation in \"selected_examples.json\".\n",
    "\n",
    "Please set the corresponding parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should correspond to parameters in training/evaluation\n",
    "max_text_length = 2300\n",
    "max_prompt_string_length = 1400\n",
    "seed=123\n",
    "original_prism_data_path = 'your/downloaded/original/prism/data/path'\n",
    "# by default, the preprocessed prism data will be saved in ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "np.random.seed(seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reorganize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Dict\n",
    "\n",
    "class Demographics(BaseModel):\n",
    "    self_description: str\n",
    "    preference: List[str] = []\n",
    "    age: str\n",
    "    gender: str\n",
    "    education: str\n",
    "    employment: str\n",
    "    marital: str\n",
    "    english_proficiency: str\n",
    "\n",
    "class UserInfo(BaseModel):\n",
    "    user_id: str\n",
    "    dialog_ids: List[str] = []\n",
    "    demographics: Demographics\n",
    "    system_string: str\n",
    "\n",
    "class DataUser(BaseModel):\n",
    "    data: Dict[str, UserInfo] = {}\n",
    "\n",
    "class Turn(BaseModel):\n",
    "    turn_nb: int\n",
    "    user_utterance: List[str] = []\n",
    "    chosen_utterance: List[str] = []\n",
    "    rejected_utterance: List[str] = []\n",
    "\n",
    "class DialogInfo(BaseModel):\n",
    "    dialog_id: str\n",
    "    user_id: str\n",
    "    turns: List[Optional[Turn]] = []\n",
    "    total_turn_nb: int\n",
    "    open_feedback: str = \"\"\n",
    "\n",
    "class DataDialog(BaseModel):\n",
    "    data: Dict[str, DialogInfo] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize user related data, skip num_completed_conversations==0\n",
    "data_user = DataUser()\n",
    "\n",
    "with open (os.path.join(original_prism_data_path, \"survey.jsonl\"), 'r') as f:\n",
    "    for line in f:\n",
    "        d = json.loads(line)\n",
    "        if d[\"num_completed_conversations\"] == 0:\n",
    "            continue\n",
    "        data_user.data[d[\"user_id\"]] = UserInfo(\n",
    "            user_id = d[\"user_id\"],\n",
    "            demographics =  Demographics(\n",
    "                self_description = d[\"self_description\"],\n",
    "                preference = [k for k, v in d[\"order_stated_prefs\"].items() if v in [1,2,3]],\n",
    "                age = d[\"age\"],\n",
    "                gender = d[\"gender\"],\n",
    "                education = d[\"education\"],\n",
    "                employment = d[\"employment_status\"],\n",
    "                marital = d[\"marital_status\"],\n",
    "                english_proficiency = d[\"english_proficiency\"]\n",
    "            ),\n",
    "            system_string = d[\"system_string\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize dialog related data\n",
    "data_dialog = DataDialog()\n",
    "\n",
    "with open (os.path.join(original_prism_data_path, \"conversations.jsonl\"), 'r') as f:\n",
    "    for line in f:\n",
    "        d = json.loads(line)\n",
    "        data_user.data[d[\"user_id\"]].dialog_ids.append(d[\"conversation_id\"])\n",
    "        data_dialog.data[d[\"conversation_id\"]] = DialogInfo(\n",
    "            dialog_id = d[\"conversation_id\"],\n",
    "            user_id = d[\"user_id\"],\n",
    "            total_turn_nb = d[\"conversation_turns\"],\n",
    "            turns = [None for _ in range(d[\"conversation_turns\"])],\n",
    "            open_feedback = d[\"open_feedback\"]\n",
    "        )\n",
    "        for utterance in d[\"conversation_history\"]:\n",
    "            # first utterance of a turn\n",
    "            if data_dialog.data[d[\"conversation_id\"]].turns[utterance[\"turn\"]] is None:\n",
    "                data_dialog.data[d[\"conversation_id\"]].turns[utterance[\"turn\"]] = Turn(\n",
    "                    turn_nb = utterance[\"turn\"]\n",
    "                )\n",
    "            # identify role\n",
    "            if utterance[\"role\"] == \"user\":\n",
    "                data_dialog.data[d[\"conversation_id\"]].turns[utterance[\"turn\"]].user_utterance.append(utterance[\"content\"])\n",
    "            elif utterance[\"if_chosen\"]:\n",
    "                data_dialog.data[d[\"conversation_id\"]].turns[utterance[\"turn\"]].chosen_utterance.append(utterance[\"content\"])\n",
    "            else:\n",
    "                data_dialog.data[d[\"conversation_id\"]].turns[utterance[\"turn\"]].rejected_utterance.append(utterance[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dict\n",
    "data_dialog = data_dialog.dict()[\"data\"]\n",
    "data_user = data_user.dict()[\"data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete dialogue c2536 by user469\n",
      "delete dialogue c4146 by user779\n"
     ]
    }
   ],
   "source": [
    "# filter out users with no qualified example\n",
    "dialog_ids = list(data_dialog.keys())\n",
    "for dialog_id in dialog_ids:\n",
    "    qualified_num = data_dialog[dialog_id][\"total_turn_nb\"]\n",
    "    for turn in data_dialog[dialog_id][\"turns\"]:\n",
    "        if (turn['user_utterance'] == [] \n",
    "            or turn['chosen_utterance'] == [] \n",
    "            or turn['rejected_utterance'] == [] \n",
    "            or len(turn[\"user_utterance\"][0]) + len(turn[\"chosen_utterance\"][0]) > max_text_length\n",
    "        ):\n",
    "            qualified_num -= 1\n",
    "        else:\n",
    "            for rejected in turn[\"rejected_utterance\"]:\n",
    "                if len(turn[\"user_utterance\"][0]) + len(rejected) > max_text_length:\n",
    "                    qualified_num -= 1\n",
    "                    break\n",
    "    # only delete when the whole dialogue is not qualifed\n",
    "    if qualified_num == 0:\n",
    "        print(\"delete dialogue\", dialog_id, \"by\", data_dialog[dialog_id][\"user_id\"])\n",
    "        data_user[data_dialog[dialog_id][\"user_id\"]][\"dialog_ids\"].remove(dialog_id)\n",
    "        if data_user[data_dialog[dialog_id][\"user_id\"]][\"dialog_ids\"] == []:\n",
    "            print(\"delete user\", data_dialog[dialog_id][\"user_id\"])\n",
    "            del data_user[data_dialog[dialog_id][\"user_id\"]]\n",
    "        del data_dialog[dialog_id]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "with open (\"./prism_data_user.json\", 'w') as f:\n",
    "    json.dump(data_user, f, indent=4)\n",
    "\n",
    "with open (\"./prism_data_dialog.json\", 'w') as f:\n",
    "    json.dump(data_dialog, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split users\n",
    "import numpy as np\n",
    "np.random.seed(seed=123)\n",
    "\n",
    "user_ids = np.array(list(data_user.keys()))\n",
    "np.random.shuffle(user_ids)\n",
    "seen_user_ids_init = user_ids[:int(len(user_ids)*0.9)]\n",
    "unseen_user_ids_init = user_ids[int(len(user_ids)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split seen users' dialogs into train/test; add unseen to test\n",
    "train_dialog_ids = np.array([])\n",
    "test_dialog_ids = np.array([])\n",
    "\n",
    "seen_user_ids = []\n",
    "unseen_user_ids = []\n",
    "\n",
    "for user_id in seen_user_ids_init:\n",
    "    to_choose_from = np.array(data_user[user_id][\"dialog_ids\"])\n",
    "    np.random.shuffle(to_choose_from)\n",
    "    train_dialog_ids = np.concatenate((train_dialog_ids, to_choose_from[:int(len(to_choose_from)*0.9)]))\n",
    "    test_dialog_ids = np.concatenate((test_dialog_ids, to_choose_from[int(len(to_choose_from)*0.9):]))\n",
    "    # move users with no dialog in train to unseen, because int(1*0.9)=0\n",
    "    if len(to_choose_from) > 1:\n",
    "        seen_user_ids.append(user_id)\n",
    "    else:\n",
    "        unseen_user_ids.append(user_id)\n",
    "\n",
    "for user_id in unseen_user_ids_init:\n",
    "    test_dialog_ids = np.concatenate((test_dialog_ids, np.array(data_user[user_id][\"dialog_ids\"])))\n",
    "    unseen_user_ids.append(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "print(len(seen_user_ids))\n",
    "print(len(unseen_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json, assign our user ids, 0=unseem, 1...=seen\n",
    "split_ids = {\"train_dialog_ids\": list(train_dialog_ids),\n",
    "             \"test_dialog_ids\": list(test_dialog_ids),\n",
    "             \"seen_user_ids\": {k:i+1 for i, k in enumerate(seen_user_ids)},\n",
    "             \"unseen_user_ids\": {k: 0 for k in unseen_user_ids}\n",
    "            }\n",
    "with open (\"./prism_split_ids.json\", 'w') as f:\n",
    "    json.dump(split_ids, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select promptsï¼šselect 50 dialogues in test split from 25 seen users & 25 unseen users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dialogues in test split and organize into {user_id: [dialog_id]}\n",
    "test_dict = {}\n",
    "\n",
    "for dialog_id in split_ids[\"test_dialog_ids\"]:\n",
    "    user_id = data_dialog[dialog_id][\"user_id\"]\n",
    "    if user_id not in test_dict.keys():\n",
    "        test_dict[user_id] = [dialog_id]\n",
    "    else:\n",
    "        test_dict[user_id].append(dialog_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 25 seen & 25 unseen users\n",
    "import random\n",
    "\n",
    "seen_users_keys = list(split_ids[\"seen_user_ids\"].keys())  # key = original user id in prism dataset\n",
    "random.shuffle(seen_users_keys)\n",
    "seen_25_user_ids = {k: split_ids[\"seen_user_ids\"][k] for k in seen_users_keys[:25]}\n",
    "\n",
    "unseen_users_keys = list(split_ids[\"unseen_user_ids\"])\n",
    "random.shuffle(unseen_users_keys)\n",
    "unseen_25_user_ids = {k: split_ids[\"unseen_user_ids\"][k] for k in unseen_users_keys[:25]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 1 dialog from each user\n",
    "seen_dialogs_from25 = []\n",
    "unseen_dialogs_from25 = []\n",
    "\n",
    "for user_id in seen_25_user_ids:\n",
    "    seen_dialogs_from25.append(random.choice(test_dict[user_id]))\n",
    "    \n",
    "for user_id in unseen_25_user_ids:\n",
    "    unseen_dialogs_from25.append(random.choice(test_dict[user_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectedTurn(BaseModel):\n",
    "    history: str\n",
    "    user_utterance: str\n",
    "    chosen_utterance: str\n",
    "    rejected_utterance: str\n",
    "    turn_nb: int\n",
    "\n",
    "class Demographics(BaseModel):\n",
    "    self_description: str\n",
    "    preference: List[str] = []\n",
    "    age: str\n",
    "    gender: str\n",
    "    education: str\n",
    "    employment: str\n",
    "    marital: str\n",
    "    english_proficiency: str\n",
    "\n",
    "class SelectedDialog(BaseModel):\n",
    "    user_id: str\n",
    "    our_id: int\n",
    "    dialog_id: str\n",
    "    turns: Dict[int, SelectedTurn] = {}  # turn_nb can have skips\n",
    "    open_feedback: str\n",
    "    demographics: Demographics\n",
    "    system_string: str\n",
    "\n",
    "class SelectedExamples(BaseModel):\n",
    "    data: Dict[str, SelectedDialog] = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_examples = SelectedExamples()\n",
    "\n",
    "dialog_ids = seen_dialogs_from25 + unseen_dialogs_from25\n",
    "user_ids = seen_25_user_ids\n",
    "user_ids.update(unseen_25_user_ids)\n",
    "\n",
    "total_turn_num = 0\n",
    "seen_turn_num = 0\n",
    "\n",
    "for dialog_id in dialog_ids:\n",
    "    selected_dialog = SelectedDialog(\n",
    "        user_id = data_dialog[dialog_id][\"user_id\"],\n",
    "        our_id = user_ids[data_dialog[dialog_id][\"user_id\"]],\n",
    "        dialog_id = dialog_id,\n",
    "        turns = {},\n",
    "        open_feedback = data_dialog[dialog_id][\"open_feedback\"],\n",
    "        demographics = Demographics(**data_user[data_dialog[dialog_id][\"user_id\"]][\"demographics\"]),\n",
    "        system_string = data_user[data_dialog[dialog_id][\"user_id\"]][\"system_string\"]\n",
    "    )\n",
    "\n",
    "    history = \"\"\n",
    "    for turn in data_dialog[dialog_id][\"turns\"]:\n",
    "        # add user utterance to history\n",
    "        history += f\"<|start_header_id|>user<|end_header_id|>\\n\\n{turn['user_utterance'][0]}<|eot_id|>\\n\"\n",
    "\n",
    "        # prepare examples, skip empty or too long examples\n",
    "        if (    turn['user_utterance'] != [] \n",
    "            and turn['chosen_utterance'] != [] \n",
    "            and len(turn[\"user_utterance\"][0]) + len(turn[\"chosen_utterance\"][0]) < max_text_length\n",
    "        ):  \n",
    "            selected_turn = SelectedTurn(\n",
    "                history = history,\n",
    "                user_utterance = turn[\"user_utterance\"][0],\n",
    "                chosen_utterance = turn[\"chosen_utterance\"][0],\n",
    "                rejected_utterance = \"\" if turn[\"rejected_utterance\"] == [] else turn[\"rejected_utterance\"][0],\n",
    "                turn_nb = turn[\"turn_nb\"]\n",
    "            )\n",
    "            selected_dialog.turns[turn[\"turn_nb\"]] = selected_turn\n",
    "            \n",
    "            total_turn_num += 1\n",
    "            if dialog_id in seen_dialogs_from25:\n",
    "                seen_turn_num += 1\n",
    "\n",
    "        # add the first chosen utterance to history for next turn\n",
    "        if turn['chosen_utterance'] != []:\n",
    "            history += f\"<|start_header_id|>assistant<|end_header_id|>\\n\\n{turn['chosen_utterance'][0]}<|eot_id|>\\n\"\n",
    "\n",
    "    selected_examples.data[dialog_id] = selected_dialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"./prism_selected_examples.json\", 'w') as f:\n",
    "   json.dump(selected_examples.dict()[\"data\"], f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
